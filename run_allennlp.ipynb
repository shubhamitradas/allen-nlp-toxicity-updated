{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shubhamitradas/allen-nlp-toxicity-updated/blob/master/run_allennlp.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "I368FzhjrvKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "649d5e90-a2ab-4db5-db21-bb9b57a1a73d"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shubhamitradas/allen-nlp-toxicity-updated.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'allen-nlp-toxicity-updated'...\n",
            "remote: Counting objects: 243, done.\u001b[K\n",
            "remote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (243/243), 43.47 KiB | 10.87 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uIHqGoS0ubRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f64c2ba-b0f0-4d96-979e-517e15841993"
      },
      "cell_type": "code",
      "source": [
        "%cd "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8TBUqA3WuTKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "aea24aaf-cc12-4bf6-f98f-3118a530449e"
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Counting objects: 6, done.\u001b[K\r\n",
            "remote: Compressing objects:  25% (1/4)   \u001b[K\rremote: Compressing objects:  50% (2/4)   \u001b[K\rremote: Compressing objects:  75% (3/4)   \u001b[K\rremote: Compressing objects: 100% (4/4)   \u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\r\n",
            "remote: Total 6 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\r\n",
            "Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\r\n",
            "From https://github.com/shubhamitradas/allen-nlp-toxicity-updated\r\n",
            "   6ee5bb2..3348688  master     -> origin/master\n",
            "Updating 6ee5bb2..3348688\n",
            "Fast-forward\n",
            " toxic/service/predictors/predictor.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2wHrwhSBsnGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gvwm0EHtsp5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "acd5d432-4aa2-4195-c931-1cd3f68063ff"
      },
      "cell_type": "code",
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\r\n",
            "-rw-r--r-- 1 root root 3997 Jul 20 07:56 README.md\r\n",
            "-rw-r--r-- 1 root root 1149 Jul 20 07:56 boe.json\r\n",
            "-rw-r--r-- 1 root root 1397 Jul 20 07:56 baseline.json\r\n",
            "drwxr-xr-x 6 root root 4096 Jul 20 08:06 toxic\r\n",
            "-rw-r--r-- 1 root root    1 Jul 20 08:06 __init__.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LiVQsYNpssLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ef2a0c3-2235-4da2-9d82-dc66fb8e63e3"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train_toxic.csv')\n",
        "print(len(train_df))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "159571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_wgKB-3tIta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "35865370-27dc-4adb-f27a-f43a63c2ff21"
      },
      "cell_type": "code",
      "source": [
        "train_df.drop(['id'],axis=1,inplace=True)\n",
        "train = train_df.iloc[0:143614,]\n",
        "val   = train_df.iloc[143615:159571,]\n",
        "print(train_df.columns)\n",
        "train.to_csv('train.csv',header=None)\n",
        "val.to_csv('validate.csv',header=None)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
            "       'identity_hate'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AFvBw_sguslq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa516abd-c3df-40c2-c575-710f21fe4377"
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%cd allen-nlp-toxicity-updated/toxic/data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\r\n",
            "/content/allen-nlp-toxicity-updated/toxic/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z_ijZ5QxvbbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir train test validate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Arx4IYRzvd51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c874e1d9-4e43-4082-fe3c-1555ad41009e"
      },
      "cell_type": "code",
      "source": [
        "%cd"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HkWipCFPvihG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!cp train.csv allen-nlp-toxicity-updated/toxic/data/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRkFVxJuvrc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a7946466-1c6a-4548-d5bc-297c8111c6f0"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('test_toxic.csv')\n",
        "print(test.isnull().sum(axis=0))\n",
        "\n",
        "test.comment_text.iloc[55142] = \"Null\"\n",
        "test.to_csv('test1_toxic.csv',index=None)\n",
        "!cp test1_toxic.csv allen-nlp-toxicity-updated/toxic/data/test/test_toxic.csv"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id              0\n",
            "comment_text    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3pdp6SLPvuMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp validate.csv allen-nlp-toxicity-updated/toxic/data/validate/val.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XoD7Kx1Zwmq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6k5_89B3v9bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3165
        },
        "outputId": "86c05ea4-9fc1-497e-f718-db337719531a"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/allen-nlp-toxicity-updated\n",
        "!allennlp train --include-package toxic baseline.json -s /tmp1/ --recover"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/allen-nlp-toxicity-updated\n",
            "2018-07-24 07:04:27,018 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2018-07-24 07:04:27,018 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2018-07-24 07:04:27,019 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2018-07-24 07:04:27,020 - INFO - allennlp.common.checks - Pytorch version: 0.4.0\n",
            "2018-07-24 07:04:27,021 - INFO - allennlp.commands.train - Recovering from prior training at /tmp1/.\n",
            "2018-07-24 07:04:27,060 - INFO - allennlp.common.params - dataset_reader.type = toxic\n",
            "2018-07-24 07:04:27,060 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = word\n",
            "2018-07-24 07:04:27,060 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.type = spacy\n",
            "2018-07-24 07:04:27,061 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.language = en_core_web_sm\n",
            "2018-07-24 07:04:27,061 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.pos_tags = False\n",
            "2018-07-24 07:04:27,061 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.parse = False\n",
            "2018-07-24 07:04:27,061 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.ner = False\n",
            "2018-07-24 07:04:27,417 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_filter.type = pass_through\n",
            "2018-07-24 07:04:27,418 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_stemmer.type = pass_through\n",
            "2018-07-24 07:04:27,418 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = None\n",
            "2018-07-24 07:04:27,418 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = None\n",
            "2018-07-24 07:04:27,418 - INFO - allennlp.common.params - dataset_reader.max_length = 5000\n",
            "2018-07-24 07:04:27,418 - INFO - allennlp.common.params - dataset_reader.fill_in_empty_labels = False\n",
            "2018-07-24 07:04:27,419 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2018-07-24 07:04:27,419 - INFO - allennlp.common.params - train_data_path = /content/allen-nlp-toxicity-updated/toxic/data/train/train.csv\n",
            "2018-07-24 07:04:27,419 - INFO - allennlp.commands.train - Reading training data from /content/allen-nlp-toxicity-updated/toxic/data/train/train.csv\n",
            "2191it [00:04, 460.62it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "143614it [05:48, 411.86it/s]\n",
            "2018-07-24 07:10:16,116 - INFO - allennlp.common.params - validation_data_path = /content/allen-nlp-toxicity-updated/toxic/data/validate/val.csv\n",
            "2018-07-24 07:10:16,116 - INFO - allennlp.commands.train - Reading validation data from /content/allen-nlp-toxicity-updated/toxic/data/validate/val.csv\n",
            "3560it [00:07, 454.47it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15956it [00:35, 453.90it/s]\n",
            "2018-07-24 07:10:51,270 - INFO - allennlp.common.params - test_data_path = /content/allen-nlp-toxicity-updated/toxic/data/test/test_toxic.csv\n",
            "2018-07-24 07:10:51,270 - INFO - allennlp.commands.train - Reading test data from /content/allen-nlp-toxicity-updated/toxic/data/test/test_toxic.csv\n",
            "13974it [00:36, 386.42it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "153165it [06:14, 409.32it/s]\n",
            "2018-07-24 07:17:05,460 - INFO - allennlp.commands.train - Creating a vocabulary using train, validation, test data.\n",
            "2018-07-24 07:17:05,461 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2018-07-24 07:17:05,461 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2018-07-24 07:17:05,461 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2018-07-24 07:17:05,461 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2018-07-24 07:17:05,461 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2018-07-24 07:17:05,462 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2018-07-24 07:17:05,462 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "15914it [00:03, 4869.64it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "312735it [01:03, 4918.51it/s]\n",
            "2018-07-24 07:18:11,826 - INFO - allennlp.common.params - model.type = toxic\n",
            "2018-07-24 07:18:11,826 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2018-07-24 07:18:11,826 - INFO - allennlp.common.params - model.text_field_embedder.embedder_to_indexer_map = None\n",
            "2018-07-24 07:18:11,826 - INFO - allennlp.common.params - model.text_field_embedder.tokens.type = embedding\n",
            "2018-07-24 07:18:11,827 - INFO - allennlp.common.params - model.text_field_embedder.tokens.num_embeddings = None\n",
            "2018-07-24 07:18:11,827 - INFO - allennlp.common.params - model.text_field_embedder.tokens.vocab_namespace = tokens\n",
            "2018-07-24 07:18:11,827 - INFO - allennlp.common.params - model.text_field_embedder.tokens.embedding_dim = 100\n",
            "2018-07-24 07:18:11,827 - INFO - allennlp.common.params - model.text_field_embedder.tokens.pretrained_file = https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\n",
            "2018-07-24 07:18:11,827 - INFO - allennlp.common.params - model.text_field_embedder.tokens.projection_dim = None\n",
            "2018-07-24 07:18:11,828 - INFO - allennlp.common.params - model.text_field_embedder.tokens.trainable = False\n",
            "2018-07-24 07:18:11,828 - INFO - allennlp.common.params - model.text_field_embedder.tokens.padding_index = None\n",
            "2018-07-24 07:18:11,828 - INFO - allennlp.common.params - model.text_field_embedder.tokens.max_norm = None\n",
            "2018-07-24 07:18:11,828 - INFO - allennlp.common.params - model.text_field_embedder.tokens.norm_type = 2.0\n",
            "2018-07-24 07:18:11,828 - INFO - allennlp.common.params - model.text_field_embedder.tokens.scale_grad_by_freq = False\n",
            "2018-07-24 07:18:11,828 - INFO - allennlp.common.params - model.text_field_embedder.tokens.sparse = False\n",
            "2018-07-24 07:18:11,903 - INFO - allennlp.modules.token_embedders.embedding - Reading embeddings from file\n",
            "2018-07-24 07:18:12,089 - INFO - allennlp.common.file_utils - https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz not found in cache, downloading to /tmp/tmpgrmh7ub_\n",
            " 98%|#########8| 131859456/134300425 [00:03<00:00, 39925130.81B/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|##########| 134300425/134300425 [00:03<00:00, 37193504.10B/s]\r\n",
            "2018-07-24 07:18:15,983 - INFO - allennlp.common.file_utils - copying /tmp/tmpgrmh7ub_ to cache at /content/.allennlp/datasets/a61c9a97077e5be80b5473a9274467fd034b5b9779c81d8de7a3dc42dc882612.9b668cee1337bb1f7412a189dada21c5dda914dd6dd91bc24a5d437b5949cbaf\n",
            "2018-07-24 07:18:16,360 - INFO - allennlp.common.file_utils - creating metadata file for /content/.allennlp/datasets/a61c9a97077e5be80b5473a9274467fd034b5b9779c81d8de7a3dc42dc882612.9b668cee1337bb1f7412a189dada21c5dda914dd6dd91bc24a5d437b5949cbaf\n",
            "2018-07-24 07:18:16,360 - INFO - allennlp.common.file_utils - removing temp file /tmp/tmpgrmh7ub_\n",
            "2018-07-24 07:18:25,168 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer\n",
            "2018-07-24 07:18:27,107 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
            "2018-07-24 07:18:27,107 - INFO - allennlp.common.params - model.encoder.batch_first = True\n",
            "2018-07-24 07:18:27,108 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-24 07:18:27,108 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-24 07:18:27,108 - INFO - allennlp.common.params - model.encoder.bidirectional = True\n",
            "2018-07-24 07:18:27,108 - INFO - allennlp.common.params - model.encoder.input_size = 100\n",
            "2018-07-24 07:18:27,108 - INFO - allennlp.common.params - model.encoder.hidden_size = 100\n",
            "2018-07-24 07:18:27,108 - INFO - allennlp.common.params - model.encoder.num_layers = 2\n",
            "2018-07-24 07:18:27,109 - INFO - allennlp.common.params - model.encoder.dropout = 0.2\n",
            "2018-07-24 07:18:27,109 - INFO - allennlp.common.params - model.encoder.batch_first = True\n",
            "2018-07-24 07:18:27,113 - INFO - allennlp.common.params - model.classifier_feedforward.input_dim = 200\n",
            "2018-07-24 07:18:27,114 - INFO - allennlp.common.params - model.classifier_feedforward.num_layers = 2\n",
            "2018-07-24 07:18:27,114 - INFO - allennlp.common.params - model.classifier_feedforward.hidden_dims = [200, 6]\n",
            "2018-07-24 07:18:27,114 - INFO - allennlp.common.params - model.classifier_feedforward.activations = ['tanh', 'linear']\n",
            "2018-07-24 07:18:27,114 - INFO - allennlp.common.params - model.classifier_feedforward.dropout = [0.2, 0.0]\n",
            "2018-07-24 07:18:27,115 - INFO - allennlp.common.params - model.initializer = []\n",
            "2018-07-24 07:18:27,115 - INFO - allennlp.common.params - model.regularizer = []\n",
            "2018-07-24 07:18:27,116 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2018-07-24 07:18:27,116 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2018-07-24 07:18:27,116 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.0.bias\n",
            "2018-07-24 07:18:27,116 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.0.weight\n",
            "2018-07-24 07:18:27,117 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.1.bias\n",
            "2018-07-24 07:18:27,117 - INFO - allennlp.nn.initializers -    classifier_feedforward._linear_layers.1.weight\n",
            "2018-07-24 07:18:27,117 - INFO - allennlp.nn.initializers -    encoder._module.bias_hh_l0\n",
            "2018-07-24 07:18:27,117 - INFO - allennlp.nn.initializers -    encoder._module.bias_hh_l0_reverse\n",
            "2018-07-24 07:18:27,117 - INFO - allennlp.nn.initializers -    encoder._module.bias_hh_l1\n",
            "2018-07-24 07:18:27,117 - INFO - allennlp.nn.initializers -    encoder._module.bias_hh_l1_reverse\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.bias_ih_l0\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.bias_ih_l0_reverse\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.bias_ih_l1\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.bias_ih_l1_reverse\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.weight_hh_l0\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.weight_hh_l0_reverse\n",
            "2018-07-24 07:18:27,118 - INFO - allennlp.nn.initializers -    encoder._module.weight_hh_l1\n",
            "2018-07-24 07:18:27,119 - INFO - allennlp.nn.initializers -    encoder._module.weight_hh_l1_reverse\n",
            "2018-07-24 07:18:27,119 - INFO - allennlp.nn.initializers -    encoder._module.weight_ih_l0\n",
            "2018-07-24 07:18:27,119 - INFO - allennlp.nn.initializers -    encoder._module.weight_ih_l0_reverse\n",
            "2018-07-24 07:18:27,119 - INFO - allennlp.nn.initializers -    encoder._module.weight_ih_l1\n",
            "2018-07-24 07:18:27,119 - INFO - allennlp.nn.initializers -    encoder._module.weight_ih_l1_reverse\n",
            "2018-07-24 07:18:27,119 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_tokens.weight\n",
            "2018-07-24 07:18:27,120 - INFO - allennlp.common.params - iterator.type = bucket\n",
            "2018-07-24 07:18:27,120 - INFO - allennlp.common.params - iterator.sorting_keys = [['text', 'num_tokens']]\n",
            "2018-07-24 07:18:27,120 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n",
            "2018-07-24 07:18:27,120 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n",
            "2018-07-24 07:18:27,120 - INFO - allennlp.common.params - iterator.batch_size = 64\n",
            "2018-07-24 07:18:27,121 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2018-07-24 07:18:27,121 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2018-07-24 07:18:27,121 - INFO - allennlp.common.params - trainer.patience = 10\n",
            "2018-07-24 07:18:27,121 - INFO - allennlp.common.params - trainer.validation_metric = +f1\n",
            "2018-07-24 07:18:27,121 - INFO - allennlp.common.params - trainer.num_epochs = 3\n",
            "2018-07-24 07:18:27,122 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2018-07-24 07:18:27,122 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2018-07-24 07:18:27,122 - INFO - allennlp.common.params - trainer.grad_clipping = 5.0\n",
            "2018-07-24 07:18:27,122 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2018-07-24 07:18:32,584 - INFO - allennlp.common.params - trainer.optimizer.type = adagrad\n",
            "2018-07-24 07:18:32,585 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2018-07-24 07:18:32,585 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2018-07-24 07:18:32,585 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2018-07-24 07:18:32,590 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = None\n",
            "2018-07-24 07:18:32,590 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2018-07-24 07:18:32,590 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2018-07-24 07:18:32,590 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2018-07-24 07:18:32,591 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2018-07-24 07:18:32,602 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2018-07-24 07:18:32,603 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2018-07-24 07:18:32,603 - INFO - allennlp.training.trainer - Epoch 0/2\n",
            "2018-07-24 07:18:32,603 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 10555.372\n",
            "2018-07-24 07:18:32,922 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 514\n",
            "  0%|          | 0/2244 [00:00<?, ?it/s]2018-07-24 07:18:32,924 - INFO - allennlp.training.trainer - Training\n",
            "precision: 0.0214, recall: 0.0243, f1: 0.0227, loss: 0.2165 ||:   1%|          | 14/2244 [00:49<2:11:20,  3.53s/it]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "precision: 0.7389, recall: 0.4524, f1: 0.5612, loss: 0.0750 ||:  74%|#######3  | 1660/2244 [03:50<01:20,  7.22it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "precision: 0.7531, recall: 0.4781, f1: 0.5849, loss: 0.0719 ||: 100%|##########| 2244/2244 [04:53<00:00,  7.63it/s]\n",
            "2018-07-24 07:23:26,921 - INFO - allennlp.training.trainer - Validating\n",
            "precision: 0.7873, recall: 0.5280, f1: 0.6321, loss: 0.0668 ||: 100%|##########| 250/250 [00:22<00:00, 11.23it/s]\n",
            "2018-07-24 07:23:50,513 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to '/tmp1//best.th'.\n",
            "2018-07-24 07:23:51,769 - INFO - allennlp.training.trainer - Training loss : 0.071927    Validation loss : 0.066793 \n",
            "2018-07-24 07:23:51,770 - INFO - allennlp.training.trainer - Training recall : 0.478148    Validation recall : 0.528027 \n",
            "2018-07-24 07:23:51,771 - INFO - allennlp.training.trainer - Training f1 : 0.584919    Validation f1 : 0.632109 \n",
            "2018-07-24 07:23:51,771 - INFO - allennlp.training.trainer - Training precision : 0.753085    Validation precision : 0.787296 \n",
            "2018-07-24 07:23:51,771 - INFO - allennlp.training.trainer - Epoch duration: 00:05:19\n",
            "2018-07-24 07:23:51,771 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:10:38\n",
            "2018-07-24 07:23:51,772 - INFO - allennlp.training.trainer - Epoch 1/2\n",
            "2018-07-24 07:23:51,772 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 10897.192\n",
            "2018-07-24 07:23:52,162 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 3086\n",
            "  0%|          | 0/2244 [00:00<?, ?it/s]2018-07-24 07:23:52,165 - INFO - allennlp.training.trainer - Training\n",
            "precision: 0.7891, recall: 0.5537, f1: 0.6508, loss: 0.0643 ||:   1%|1         | 29/2244 [00:09<11:48,  3.13it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "precision: 0.7927, recall: 0.5665, f1: 0.6608, loss: 0.0599 ||:  75%|#######4  | 1680/2244 [03:12<01:04,  8.74it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "precision: 0.7925, recall: 0.5690, f1: 0.6624, loss: 0.0594 ||: 100%|##########| 2244/2244 [04:13<00:00,  8.86it/s]\n",
            "2018-07-24 07:28:05,556 - INFO - allennlp.training.trainer - Validating\n",
            "precision: 0.8088, recall: 0.5418, f1: 0.6489, loss: 0.0613 ||: 100%|##########| 250/250 [00:17<00:00, 14.08it/s]\n",
            "2018-07-24 07:28:24,311 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to '/tmp1//best.th'.\n",
            "2018-07-24 07:28:25,663 - INFO - allennlp.training.trainer - Training loss : 0.059434    Validation loss : 0.061252 \n",
            "2018-07-24 07:28:25,664 - INFO - allennlp.training.trainer - Training recall : 0.569045    Validation recall : 0.541760 \n",
            "2018-07-24 07:28:25,664 - INFO - allennlp.training.trainer - Training f1 : 0.662433    Validation f1 : 0.648875 \n",
            "2018-07-24 07:28:25,664 - INFO - allennlp.training.trainer - Training precision : 0.792491    Validation precision : 0.808787 \n",
            "2018-07-24 07:28:25,665 - INFO - allennlp.training.trainer - Epoch duration: 00:04:33\n",
            "2018-07-24 07:28:25,665 - INFO - allennlp.training.trainer - Estimated training time remaining: 00:04:56\n",
            "2018-07-24 07:28:25,665 - INFO - allennlp.training.trainer - Epoch 2/2\n",
            "2018-07-24 07:28:25,665 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 10897.192\n",
            "2018-07-24 07:28:26,050 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 3870\n",
            "  0%|          | 0/2244 [00:00<?, ?it/s]2018-07-24 07:28:26,052 - INFO - allennlp.training.trainer - Training\n",
            "precision: 0.8369, recall: 0.6022, f1: 0.7004, loss: 0.0576 ||:   1%|1         | 31/2244 [00:11<13:07,  2.81it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "precision: 0.8064, recall: 0.5982, f1: 0.6869, loss: 0.0553 ||:  75%|#######5  | 1684/2244 [03:15<01:04,  8.63it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "precision: 0.8062, recall: 0.5971, f1: 0.6860, loss: 0.0554 ||: 100%|##########| 2244/2244 [04:14<00:00,  8.83it/s]\n",
            "2018-07-24 07:32:40,208 - INFO - allennlp.training.trainer - Validating\n",
            "precision: 0.8025, recall: 0.5673, f1: 0.6647, loss: 0.0589 ||: 100%|##########| 250/250 [00:18<00:00, 13.85it/s]\n",
            "2018-07-24 07:32:59,370 - INFO - allennlp.training.trainer - Best validation performance so far. Copying weights to '/tmp1//best.th'.\n",
            "2018-07-24 07:33:00,806 - INFO - allennlp.training.trainer - Training loss : 0.055414    Validation loss : 0.058936 \n",
            "2018-07-24 07:33:00,808 - INFO - allennlp.training.trainer - Training recall : 0.597050    Validation recall : 0.567265 \n",
            "2018-07-24 07:33:00,808 - INFO - allennlp.training.trainer - Training f1 : 0.686030    Validation f1 : 0.664696 \n",
            "2018-07-24 07:33:00,808 - INFO - allennlp.training.trainer - Training precision : 0.806175    Validation precision : 0.802538 \n",
            "2018-07-24 07:33:00,809 - INFO - allennlp.training.trainer - Epoch duration: 00:04:35\n",
            "2018-07-24 07:33:00,809 - INFO - allennlp.models.archival - archiving weights and vocabulary to /tmp1/model.tar.gz\n",
            "2018-07-24 07:33:12,342 - INFO - allennlp.commands.train - Loading the best epoch weights.\n",
            "2018-07-24 07:33:12,577 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
            "2018-07-24 07:33:12,578 - INFO - allennlp.commands.train - Metrics: {\n",
            "  \"training_duration\": \"00:14:28\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 3,\n",
            "  \"training_precision\": 0.806175324397242,\n",
            "  \"training_recall\": 0.5970504281636536,\n",
            "  \"training_f1\": 0.6860297735099578,\n",
            "  \"training_loss\": 0.05541400551698843,\n",
            "  \"validation_precision\": 0.80253766851705,\n",
            "  \"validation_recall\": 0.5672645739910314,\n",
            "  \"validation_f1\": 0.6646962233169129,\n",
            "  \"validation_loss\": 0.058936330407857895,\n",
            "  \"best_validation_f1\": 0.6646962233169129,\n",
            "  \"best_epoch\": 2\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5eK3_5R-RPmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8ec3b67-795b-4e10-ba32-9b4dc3344658"
      },
      "cell_type": "code",
      "source": [
        "%cd allen-nlp-toxicity-updated\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/allen-nlp-toxicity-updated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qvOLvm6bOGKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fdf0f991-f0b2-4a24-8598-08aa124412dd"
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Counting objects: 4, done.\u001b[K\r\n",
            "remote: Compressing objects:  25% (1/4)   \u001b[K\rremote: Compressing objects:  50% (2/4)   \u001b[K\rremote: Compressing objects:  75% (3/4)   \u001b[K\rremote: Compressing objects: 100% (4/4)   \u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\r\n",
            "remote: Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\r\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\r\n",
            "From https://github.com/shubhamitradas/allen-nlp-toxicity-updated\r\n",
            "   3348688..0999cc3  master     -> origin/master\r\n",
            "Updating 3348688..0999cc3\r\n",
            "Fast-forward\n",
            " toxic/predict.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mvmT1JgSRSrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "feb38762-284d-42c4-ba90-05af558e09ee"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "pred = pd.read_csv('/tmp1/predictions.csv')\n",
        "pred.drop(pred.index[0],inplace=True)\n",
        "pred.to_csv(\"submission.csv\",index=None)\n",
        "sub=pd.read_csv(\"submission.csv\")\n",
        "sub.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.986855</td>\n",
              "      <td>0.233326</td>\n",
              "      <td>0.885648</td>\n",
              "      <td>0.103804</td>\n",
              "      <td>0.906514</td>\n",
              "      <td>0.256649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.016469</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.004808</td>\n",
              "      <td>0.000429</td>\n",
              "      <td>0.004135</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.009932</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.004671</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>0.000655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.001156</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.000060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.004357</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.001301</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>0.000196</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
              "0  00001cee341fdb12  0.986855      0.233326  0.885648  0.103804  0.906514   \n",
              "1  0000247867823ef7  0.016469      0.000249  0.004808  0.000429  0.004135   \n",
              "2  00013b17ad220c46  0.009932      0.000210  0.004671  0.000236  0.002377   \n",
              "3  00017563c3f7919a  0.001156      0.000011  0.000409  0.000019  0.000240   \n",
              "4  00017695ad8997eb  0.004357      0.000039  0.001301  0.000070  0.000930   \n",
              "\n",
              "   identity_hate  \n",
              "0       0.256649  \n",
              "1       0.001111  \n",
              "2       0.000655  \n",
              "3       0.000060  \n",
              "4       0.000196  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "fxG0Dqy_S9eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gzip submission.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2o4K4h-TAJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('submission.csv.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1FXExpMJVNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff3853f7-18a3-4908-e04d-cb73fb93040d"
      },
      "cell_type": "code",
      "source": [
        "pred.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id</td>\n",
              "      <td>0.330123</td>\n",
              "      <td>0.102908</td>\n",
              "      <td>0.218187</td>\n",
              "      <td>0.096973</td>\n",
              "      <td>0.223132</td>\n",
              "      <td>0.119601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.986855</td>\n",
              "      <td>0.233326</td>\n",
              "      <td>0.885648</td>\n",
              "      <td>0.103804</td>\n",
              "      <td>0.906514</td>\n",
              "      <td>0.256649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.016469</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.004808</td>\n",
              "      <td>0.000429</td>\n",
              "      <td>0.004135</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.009932</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.004671</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>0.000655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.001156</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.000060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
              "0                id  0.330123      0.102908  0.218187  0.096973  0.223132   \n",
              "1  00001cee341fdb12  0.986855      0.233326  0.885648  0.103804  0.906514   \n",
              "2  0000247867823ef7  0.016469      0.000249  0.004808  0.000429  0.004135   \n",
              "3  00013b17ad220c46  0.009932      0.000210  0.004671  0.000236  0.002377   \n",
              "4  00017563c3f7919a  0.001156      0.000011  0.000409  0.000019  0.000240   \n",
              "\n",
              "   identity_hate  \n",
              "0       0.119601  \n",
              "1       0.256649  \n",
              "2       0.001111  \n",
              "3       0.000655  \n",
              "4       0.000060  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "BX6gNmiIC4cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f779ebc-fa07-413e-ed1c-4eb0f5b47125"
      },
      "cell_type": "code",
      "source": [
        "%cd"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8VWFvAVBvqQI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}